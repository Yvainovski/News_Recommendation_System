{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "import gensim\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_store = list()\n",
    "with open('./news_baseline.json','r',encoding=\"utf8\") as f :\n",
    "    ls = f.readlines()\n",
    "    for l in ls:\n",
    "        news = json.loads(l)\n",
    "        #combine sci with tech \n",
    "        if(news['category']==\"science\"):\n",
    "            news['category']=\"technology\"\n",
    "        # combine title and description\n",
    "        # to-dos\n",
    "        news_store.append(news)\n",
    "    \n",
    "news_store = pd.DataFrame(news_store)\n",
    "news_store.drop('_id', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data num: 875\n",
      "Training data num: 3503\n"
     ]
    }
   ],
   "source": [
    "# prepare training and testing data\n",
    "data = news_store.sample(frac=1.0)\n",
    "test_num = int(0.2 * data.shape[0]) # 20% percent of test data\n",
    "data_test = data[:test_num]\n",
    "data_train = data[test_num:]\n",
    "X_test_raw = data_test['description']\n",
    "Y_test = data_test['category']\n",
    "X_train_raw = data_train['description']\n",
    "Y_train = data_train['category']\n",
    "print('Test data num: {}\\nTraining data num: {}'.format(test_num,data.shape[0]-test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words: get rid of stop words and punctuation + word stemming.\n",
    "# stop = stopwords.words('english') + list(string.punctuation)\n",
    "# tok_corpus = list()\n",
    "# for sent in news_store['description']:\n",
    "#     tokenized_sent = [d for d in nltk.RegexpTokenizer(r'\\w+').tokenize(sent.lower()) if d not in stop]\n",
    "#     for i, w in enumerate(tokenized_sent):\n",
    "#         tokenized_sent[i] = SnowballStemmer('english').stem(w)\n",
    "#     tok_corpus.append(tokenized_sent) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = gensim.models.Word2Vec(tok_corpus, size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to numeric representations\n",
    "tb_vp = tf.contrib.learn.preprocessing.VocabularyProcessor(50)\n",
    "X_train_numvec = np.array(list(tb_vp.fit_transform(X_train_raw)))\n",
    "X_test_numvec = np.array(list(tb_vp.transform(X_test_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14772\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "categories = ['business','entertainment','general','health',\n",
    "            'science', 'sports']\n",
    "voc_size = len(tb_vp.vocabulary_)\n",
    "print(voc_size)\n",
    "\n",
    "def train_cnn():\n",
    "    clf = tf.contrib.learn.Estimator(model_fn=generate_cnn_model(len(categories),voc_size))\n",
    "    clf.fit(X_train, Y_train, steps=200)\n",
    "    \n",
    "    Y_pred = clf.predict(X_test)\n",
    "    \n",
    "    score = sklearn.metrics.accuracy_score(Y_test,Y_pred)\n",
    "    print(score)\n",
    "# tmp = tf.contrib.layers.embed_sequence(X_train_numvec,voc_size,50)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     res = sess.run(tmp)\n",
    "#     print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#     tf.app.run(train_cnn)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
